{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3b95e99-d137-46db-aa3d-2a719493f543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 613912</td><td>32.8</td><td>1330087</td><td>71.1</td><td>1151093</td><td>61.5</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>1149643</td><td> 8.8</td><td>8388608</td><td>64.0</td><td>1801055</td><td>13.8</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  613912 & 32.8 & 1330087 & 71.1 & 1151093 & 61.5\\\\\n",
       "\tVcells & 1149643 &  8.8 & 8388608 & 64.0 & 1801055 & 13.8\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |  613912 | 32.8 | 1330087 | 71.1 | 1151093 | 61.5 |\n",
       "| Vcells | 1149643 |  8.8 | 8388608 | 64.0 | 1801055 | 13.8 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
       "Ncells  613912 32.8 1330087    71.1 1151093  61.5\n",
       "Vcells 1149643  8.8 8388608    64.0 1801055  13.8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: data.table\n",
      "\n",
      "Loading required package: Rcpp\n",
      "\n",
      "Loading required package: ranger\n",
      "\n",
      "Loading required package: randomForest\n",
      "\n",
      "randomForest 4.7-1.1\n",
      "\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "\n",
      "Attaching package: ‘randomForest’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:ranger’:\n",
      "\n",
      "    importance\n",
      "\n",
      "\n",
      "Loading required package: lightgbm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#limpio la memoria\n",
    "rm( list=ls() )  #remove all objects\n",
    "gc()             #garbage collection\n",
    "\n",
    "require(\"data.table\")\n",
    "require(\"Rcpp\")\n",
    "\n",
    "require(\"ranger\")\n",
    "require(\"randomForest\")  #solo se usa para imputar nulos\n",
    "\n",
    "require(\"lightgbm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f5b1bdc-06ef-4b80-8ba5-63950728c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kdatasetinput <- \"alt_c2_reparacNA_feinicialymio_rank0fijo.csv.gz\"\n",
    "#kdatasetoutput <- \"alt_c2_reparacNA_feinicialymioylag1ylag2_rank0fijo.csv.gz\"\n",
    "\n",
    "kdatasetinput <- \"alt_c2_reparacNA_feinicialymio_deflacion.csv.gz\"\n",
    "kdatasetoutput <- \"alt_c2_reparacNA_feinicialymioylag1_deflacion.csv.gz\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d04f110-63b2-4ea0-8dc6-9f36b25a759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## INICIO PARAMETROS ################\n",
    "klag1 <- TRUE\n",
    "klag2 <- FALSE\n",
    "klag3 <- FALSE\n",
    "kTendencias <- FALSE\n",
    "kRandomForest <- FALSE\n",
    "kCanaritosAsesinos <- FALSE\n",
    "############## FIN PARAMETROS ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85693083-effa-47a4-95e0-328942c97783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setwd(\"C:/_MCD/Labo1/code\")  #Establezco el Working Directory\n",
    "setwd(\"~/buckets/b1/\")\n",
    "\n",
    "#cargo el dataset\n",
    "dataset  <- fread(paste0(\"./datasets/\",kdatasetinput))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1db2a64a-3663-40d8-beb2-301bbcc42747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "#se calculan para los 6 meses previos el minimo, maximo y tendencia calculada con cuadrados minimos\n",
    "#la formula de calculo de la tendencia puede verse en https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Book%3A_Introductory_Statistics_(Shafer_and_Zhang)/10%3A_Correlation_and_Regression/10.04%3A_The_Least_Squares_Regression_Line\n",
    "#para la maxíma velocidad esta funcion esta escrita en lenguaje C, y no en la porqueria de R o Python\n",
    "\n",
    "cppFunction('NumericVector fhistC(NumericVector pcolumna, IntegerVector pdesde ) \n",
    "{\n",
    "  /* Aqui se cargan los valores para la regresion */\n",
    "  double  x[100] ;\n",
    "  double  y[100] ;\n",
    "\n",
    "  int n = pcolumna.size();\n",
    "  NumericVector out( 5*n );\n",
    "\n",
    "  for(int i = 0; i < n; i++)\n",
    "  {\n",
    "    //lag\n",
    "    if( pdesde[i]-1 < i )  out[ i + 4*n ]  =  pcolumna[i-1] ;\n",
    "    else                   out[ i + 4*n ]  =  NA_REAL ;\n",
    "\n",
    "\n",
    "    int  libre    = 0 ;\n",
    "    int  xvalor   = 1 ;\n",
    "\n",
    "    for( int j= pdesde[i]-1;  j<=i; j++ )\n",
    "    {\n",
    "       double a = pcolumna[j] ;\n",
    "\n",
    "       if( !R_IsNA( a ) ) \n",
    "       {\n",
    "          y[ libre ]= a ;\n",
    "          x[ libre ]= xvalor ;\n",
    "          libre++ ;\n",
    "       }\n",
    "\n",
    "       xvalor++ ;\n",
    "    }\n",
    "\n",
    "    /* Si hay al menos dos valores */\n",
    "    if( libre > 1 )\n",
    "    {\n",
    "      double  xsum  = x[0] ;\n",
    "      double  ysum  = y[0] ;\n",
    "      double  xysum = xsum * ysum ;\n",
    "      double  xxsum = xsum * xsum ;\n",
    "      double  vmin  = y[0] ;\n",
    "      double  vmax  = y[0] ;\n",
    "\n",
    "      for( int h=1; h<libre; h++)\n",
    "      { \n",
    "        xsum  += x[h] ;\n",
    "        ysum  += y[h] ; \n",
    "        xysum += x[h]*y[h] ;\n",
    "        xxsum += x[h]*x[h] ;\n",
    "\n",
    "        if( y[h] < vmin )  vmin = y[h] ;\n",
    "        if( y[h] > vmax )  vmax = y[h] ;\n",
    "      }\n",
    "\n",
    "      out[ i ]  =  (libre*xysum - xsum*ysum)/(libre*xxsum -xsum*xsum) ;\n",
    "      out[ i + n ]    =  vmin ;\n",
    "      out[ i + 2*n ]  =  vmax ;\n",
    "      out[ i + 3*n ]  =  ysum / libre ;\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "      out[ i       ]  =  NA_REAL ; \n",
    "      out[ i + n   ]  =  NA_REAL ;\n",
    "      out[ i + 2*n ]  =  NA_REAL ;\n",
    "      out[ i + 3*n ]  =  NA_REAL ;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return  out;\n",
    "}')\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#calcula la tendencia de las variables cols de los ultimos 6 meses\n",
    "#la tendencia es la pendiente de la recta que ajusta por cuadrados minimos\n",
    "#La funcionalidad de ratioavg es autoria de  Daiana Sparta,  UAustral  2021\n",
    "\n",
    "TendenciaYmuchomas  <- function( dataset, cols, ventana=6, tendencia=TRUE, minimo=TRUE, maximo=TRUE, promedio=TRUE, \n",
    "                                 ratioavg=FALSE, ratiomax=FALSE)\n",
    "{\n",
    "  gc()\n",
    "  #Esta es la cantidad de meses que utilizo para la historia\n",
    "  ventana_regresion  <- ventana\n",
    "\n",
    "  last  <- nrow( dataset )\n",
    "\n",
    "  #creo el vector_desde que indica cada ventana\n",
    "  #de esta forma se acelera el procesamiento ya que lo hago una sola vez\n",
    "  vector_ids   <- dataset$numero_de_cliente\n",
    "\n",
    "  vector_desde  <- seq( -ventana_regresion+2,  nrow(dataset)-ventana_regresion+1 )\n",
    "  vector_desde[ 1:ventana_regresion ]  <-  1\n",
    "\n",
    "  for( i in 2:last )  if( vector_ids[ i-1 ] !=  vector_ids[ i ] ) {  vector_desde[i] <-  i }\n",
    "  for( i in 2:last )  if( vector_desde[i] < vector_desde[i-1] )  {  vector_desde[i] <-  vector_desde[i-1] }\n",
    "\n",
    "  for(  campo  in   cols )\n",
    "  {\n",
    "    nueva_col     <- fhistC( dataset[ , get(campo) ], vector_desde ) \n",
    "\n",
    "    if(tendencia)  dataset[ , paste0( campo, \"_tend\", ventana) := nueva_col[ (0*last +1):(1*last) ]  ]\n",
    "    if(minimo)     dataset[ , paste0( campo, \"_min\", ventana)  := nueva_col[ (1*last +1):(2*last) ]  ]\n",
    "    if(maximo)     dataset[ , paste0( campo, \"_max\", ventana)  := nueva_col[ (2*last +1):(3*last) ]  ]\n",
    "    if(promedio)   dataset[ , paste0( campo, \"_avg\", ventana)  := nueva_col[ (3*last +1):(4*last) ]  ]\n",
    "    if(ratioavg)   dataset[ , paste0( campo, \"_ratioavg\", ventana)  := get(campo) /nueva_col[ (3*last +1):(4*last) ]  ]\n",
    "    if(ratiomax)   dataset[ , paste0( campo, \"_ratiomax\", ventana)  := get(campo) /nueva_col[ (2*last +1):(3*last) ]  ]\n",
    "  }\n",
    "\n",
    "}\n",
    "#------------------------------------------------------------------------------\n",
    "#agrega al dataset nuevas variables {0,1} que provienen de las hojas de un Random Forest\n",
    "\n",
    "AgregaVarRandomForest  <- function( num.trees, max.depth, min.node.size, mtry)\n",
    "{\n",
    "  gc()\n",
    "  dataset[ , clase01:= ifelse( clase_ternaria==\"CONTINUA\", 0, 1 ) ]\n",
    "\n",
    "  campos_buenos  <- setdiff( colnames(dataset), c(\"clase_ternaria\" ) )\n",
    "\n",
    "  dataset_rf  <- copy( dataset[ , campos_buenos, with=FALSE] )\n",
    "  azar  <- runif( nrow(dataset_rf) )\n",
    "  dataset_rf[ , entrenamiento := as.integer( foto_mes>= 202009 &  foto_mes<= 202101 & ( clase01==1 | azar < 0.10 )) ]\n",
    "\n",
    "  #imputo los nulos, ya que ranger no acepta nulos\n",
    "  #Leo Breiman, ¿por que le temias a los nulos?\n",
    "  dataset_rf  <- na.roughfix( dataset_rf )\n",
    "\n",
    "  campos_buenos  <- setdiff( colnames(dataset_rf), c(\"clase_ternaria\",\"entrenamiento\" ) )\n",
    "  modelo  <- ranger( formula= \"clase01 ~ .\",\n",
    "                     data=  dataset_rf[ entrenamiento==1L, campos_buenos, with=FALSE  ] ,\n",
    "                     classification= TRUE,\n",
    "                     probability=   FALSE,\n",
    "                     num.trees=     num.trees,\n",
    "                     max.depth=     max.depth,\n",
    "                     min.node.size= min.node.size,\n",
    "                     mtry=          mtry\n",
    "                   )\n",
    "\n",
    "  rfhojas  <- predict( object= modelo, \n",
    "                       data= dataset_rf[ , campos_buenos, with=FALSE ],\n",
    "                       predict.all= TRUE,    #entrega la prediccion de cada arbol\n",
    "                       type= \"terminalNodes\" #entrega el numero de NODO el arbol\n",
    "                     )\n",
    "\n",
    "  for( arbol in 1:num.trees )\n",
    "  {\n",
    "    hojas_arbol  <- unique(  rfhojas$predictions[  , arbol  ] )\n",
    "\n",
    "    for( pos in 1:length(hojas_arbol) )\n",
    "    {\n",
    "      nodo_id  <- hojas_arbol[ pos ]  #el numero de nodo de la hoja, estan salteados\n",
    "      dataset[  ,  paste0( \"rf_\", sprintf( \"%03d\", arbol ), \"_\", sprintf( \"%03d\", nodo_id ) ) := 0L ]\n",
    "\n",
    "      dataset[ which( rfhojas$predictions[ , arbol] == nodo_id ,  ), \n",
    "               paste0( \"rf_\", sprintf( \"%03d\", arbol ), \"_\", sprintf( \"%03d\", nodo_id ) ) := 1L ]\n",
    "    }\n",
    "  }\n",
    "\n",
    "  rm( dataset_rf )\n",
    "  dataset[ , clase01 := NULL ]\n",
    "\n",
    "  gc()\n",
    "}\n",
    "#------------------------------------------------------------------------------\n",
    "VPOS_CORTE  <- c()\n",
    "\n",
    "fganancia_lgbm_meseta  <- function(probs, datos) \n",
    "{\n",
    "  vlabels  <- get_field(datos, \"label\")\n",
    "  vpesos   <- get_field(datos, \"weight\")\n",
    "\n",
    "  tbl  <- as.data.table( list( \"prob\"=probs, \"gan\"= ifelse( vlabels==1 & vpesos > 1, 78000, -2000 ) ) )\n",
    "\n",
    "  setorder( tbl, -prob )\n",
    "  tbl[ , posicion := .I ]\n",
    "  tbl[ , gan_acum :=  cumsum( gan ) ]\n",
    "  setorder( tbl, -gan_acum )   #voy por la meseta\n",
    "\n",
    "  gan  <- mean( tbl[ 1:500,  gan_acum] )  #meseta de tamaño 500\n",
    "\n",
    "  pos_meseta  <- tbl[ 1:500,  median(posicion)]\n",
    "  VPOS_CORTE  <<- c( VPOS_CORTE, pos_meseta )\n",
    "\n",
    "  return( list( \"name\"= \"ganancia\", \n",
    "                \"value\"=  gan,\n",
    "                \"higher_better\"= TRUE ) )\n",
    "}\n",
    "#------------------------------------------------------------------------------\n",
    "#Elimina del dataset las variables que estan por debajo de la capa geologica de canaritos\n",
    "#se llama varias veces, luego de agregar muchas variables nuevas, para ir reduciendo la cantidad de variables\n",
    "# y así hacer lugar a nuevas variables importantes\n",
    "\n",
    "GVEZ <- 1 \n",
    "\n",
    "CanaritosAsesinos  <- function( canaritos_ratio=0.2 )\n",
    "{\n",
    "  gc()\n",
    "  dataset[ , clase01:= ifelse( clase_ternaria==\"CONTINUA\", 0, 1 ) ]\n",
    "\n",
    "  for( i  in 1:(ncol(dataset)*canaritos_ratio))  dataset[ , paste0(\"canarito\", i ) :=  runif( nrow(dataset))]\n",
    "\n",
    "  campos_buenos  <- setdiff( colnames(dataset), c(\"clase_ternaria\",\"clase01\", \"foto_mes\" ) )\n",
    "\n",
    "  azar  <- runif( nrow(dataset) )\n",
    "  dataset[ , entrenamiento := foto_mes>= 202010 &  foto_mes<= 202101  & ( clase01==1 | azar < 0.10 ) ]\n",
    "\n",
    "  dtrain  <- lgb.Dataset( data=    data.matrix(  dataset[ entrenamiento==TRUE, campos_buenos, with=FALSE]),\n",
    "                          label=   dataset[ entrenamiento==TRUE, clase01],\n",
    "                          weight=  dataset[ entrenamiento==TRUE, ifelse(clase_ternaria==\"BAJA+2\", 1.0000001, 1.0)],\n",
    "                          free_raw_data= FALSE\n",
    "                        )\n",
    "\n",
    "  dvalid  <- lgb.Dataset( data=    data.matrix(  dataset[ foto_mes==202103, campos_buenos, with=FALSE]),\n",
    "                          label=   dataset[ foto_mes==202103, clase01],\n",
    "                          weight=  dataset[ foto_mes==202103, ifelse(clase_ternaria==\"BAJA+2\", 1.0000001, 1.0)],\n",
    "                          free_raw_data= FALSE\n",
    "                          )\n",
    "\n",
    "\n",
    "  param <- list( objective= \"binary\",\n",
    "                 metric= \"custom\",\n",
    "                 first_metric_only= TRUE,\n",
    "                 boost_from_average= TRUE,\n",
    "                 feature_pre_filter= FALSE,\n",
    "                 verbosity= -100,\n",
    "                 seed= 999983,\n",
    "                 max_depth=  -1,         # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "                 min_gain_to_split= 0.0, #por ahora, lo dejo fijo\n",
    "                 lambda_l1= 0.0,         #por ahora, lo dejo fijo\n",
    "                 lambda_l2= 0.0,         #por ahora, lo dejo fijo\n",
    "                 max_bin= 31,            #por ahora, lo dejo fijo\n",
    "                 num_iterations= 9999,   #un numero muy grande, lo limita early_stopping_rounds\n",
    "                 force_row_wise= TRUE,    #para que los alumnos no se atemoricen con tantos warning\n",
    "                 learning_rate= 0.065, \n",
    "                 feature_fraction= 1.0,   #lo seteo en 1 para que las primeras variables del dataset no se vean opacadas\n",
    "                 min_data_in_leaf= 260,\n",
    "                 num_leaves= 60,\n",
    "                 early_stopping_rounds= 200 )\n",
    "\n",
    "  modelo  <- lgb.train( data= dtrain,\n",
    "                        valids= list( valid= dvalid ),\n",
    "                        eval= fganancia_lgbm_meseta,\n",
    "                        param= param,\n",
    "                        verbose= -100 )\n",
    "\n",
    "  tb_importancia  <- lgb.importance( model= modelo )\n",
    "  tb_importancia[  , pos := .I ]\n",
    "\n",
    "  fwrite( tb_importancia, \n",
    "          file= paste0( \"impo_\", GVEZ ,\".txt\"),\n",
    "          sep= \"\\t\" )\n",
    "\n",
    "  GVEZ  <<- GVEZ + 1\n",
    "\n",
    "  umbral  <- tb_importancia[ Feature %like% \"canarito\", median(pos) + 2*sd(pos) ]  #Atencion corto en la mediana mas DOS desvios!!\n",
    "\n",
    "  col_utiles  <- tb_importancia[ pos < umbral & !( Feature %like% \"canarito\"),  Feature ]\n",
    "  col_utiles  <-  unique( c( col_utiles,  c(\"numero_de_cliente\",\"foto_mes\",\"clase_ternaria\",\"mes\") ) )\n",
    "  col_inutiles  <- setdiff( colnames(dataset), col_utiles )\n",
    "\n",
    "  dataset[  ,  (col_inutiles) := NULL ]\n",
    "\n",
    "}\n",
    "#------------------------------------------------------------------------------\n",
    "#agrega para cada columna de cols una nueva variable _rank  que es un numero entre 0 y 1  del ranking de esa variable ese mes\n",
    "\n",
    "Rankeador  <- function( cols )\n",
    "{\n",
    "  gc()\n",
    "  sufijo  <- \"_rank\" \n",
    "\n",
    "  for( vcol in cols )\n",
    "  {\n",
    "     dataset[ , paste0( vcol, sufijo) := frank( get(vcol), ties.method= \"random\")/ .N, \n",
    "                by= foto_mes ]\n",
    "  }\n",
    "}\n",
    "#------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39d8acbf-6ceb-4607-9127-8960920ba3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#estas son las columnas a las que se puede agregar lags o media moviles ( todas menos las obvias )\n",
    "cols_lagueables  <- copy(  setdiff( colnames(dataset), c(\"numero_de_cliente\", \"foto_mes\", \"clase_ternaria\")  ) )\n",
    "\n",
    "#ordeno el dataset por <numero_de_cliente, foto_mes> para poder hacer lags\n",
    "#  es MUY  importante esta linea\n",
    "setorder( dataset, numero_de_cliente, foto_mes )\n",
    "\n",
    "\n",
    "if( klag1 )\n",
    "{\n",
    "  #creo los campos lags de orden 1\n",
    "  dataset[ , paste0( cols_lagueables, \"_lag1\") := shift(.SD, 1, NA, \"lag\"), \n",
    "             by= numero_de_cliente, \n",
    "             .SDcols= cols_lagueables ]\n",
    "\n",
    "  #agrego los delta lags de orden 1\n",
    "  for( vcol in cols_lagueables )\n",
    "  {\n",
    "    dataset[ , paste0(vcol, \"_delta1\") := get(vcol)  - get(paste0( vcol, \"_lag1\"))  ]\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "if( klag2 )\n",
    "{\n",
    "  #creo los campos lags de orden 2\n",
    "  dataset[ , paste0( cols_lagueables, \"_lag2\") := shift(.SD, 2, NA, \"lag\"), \n",
    "             by= numero_de_cliente, \n",
    "             .SDcols= cols_lagueables ]\n",
    "\n",
    "  #agrego los delta lags de orden 2\n",
    "  for( vcol in cols_lagueables )\n",
    "  {\n",
    "    dataset[ , paste0(vcol, \"_delta2\") := get(vcol)  - get(paste0( vcol, \"_lag2\"))  ]\n",
    "  }\n",
    "}\n",
    "\n",
    "if( klag3 )\n",
    "{\n",
    "  #creo los campos lags de orden 3\n",
    "  dataset[ , paste0( cols_lagueables, \"_lag3\") := shift(.SD, 3, NA, \"lag\"), \n",
    "             by= numero_de_cliente, \n",
    "             .SDcols= cols_lagueables ]\n",
    "\n",
    "  #agrego los delta lags de orden 3\n",
    "  for( vcol in cols_lagueables )\n",
    "  {\n",
    "    dataset[ , paste0(vcol, \"_delta3\") := get(vcol)  - get(paste0( vcol, \"_lag3\"))  ]\n",
    "  }\n",
    "}\n",
    "#--------------------------------------\n",
    "#agrego las tendencias\n",
    "\n",
    "#ordeno el dataset por <numero_de_cliente, foto_mes> para poder hacer lags\n",
    "#  es MUY  importante esta linea\n",
    "setorder( dataset, numero_de_cliente, foto_mes )\n",
    "\n",
    "if( kTendencias )\n",
    "{\n",
    "  TendenciaYmuchomas( dataset, \n",
    "                      cols= cols_lagueables,\n",
    "                      ventana=   6,      # 6 meses de historia\n",
    "                      tendencia= TRUE,\n",
    "                      minimo=    FALSE,\n",
    "                      maximo=    FALSE,\n",
    "                      promedio=  TRUE,\n",
    "                      ratioavg=  FALSE,\n",
    "                      ratiomax=  FALSE  )\n",
    "}\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#Agrego variables a partir de las hojas de un Random Forest\n",
    "\n",
    "if( kRandomForest )\n",
    "{\n",
    "  AgregaVarRandomForest( num.trees = 40,\n",
    "                         max.depth = 5,\n",
    "                         min.node.size = 500,\n",
    "                         mtry = 15 )\n",
    "\n",
    "  gc()\n",
    "}\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "#Elimino las variables que no son tan importantes en el dataset\n",
    "# with great power comes grest responsability\n",
    "\n",
    "if( kCanaritosAsesinos )\n",
    "{\n",
    "  ncol( dataset )\n",
    "  CanaritosAsesinos( canaritos_ratio = 0.3 )\n",
    "  ncol( dataset )\n",
    "}\n",
    "\n",
    "#------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0543f32b-db6f-4791-8439-f7f2ef5599a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwrite( dataset,\n",
    "        file=paste0(\"./datasets/\",kdatasetoutput),\n",
    "        sep= \",\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635a0f49-58ba-48cf-8e79-634d6e81fadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0882cea-faa5-48aa-ac43-94726ea5c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncol(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
