{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2060347a-487f-4551-8774-d868d4ad01e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source( \"~/labo/src/lightgbm/z623_lightgbm_binaria_BO.r\" )\n",
    "# Este script esta pensado para correr en Google Cloud\n",
    "#   8 vCPU\n",
    "#  32 GB memoria RAM\n",
    "# 256 GB espacio en disco\n",
    "\n",
    "# se entrena con POS =  { BAJA+1, BAJA+2 }\n",
    "# Optimizacion Bayesiana de hiperparametros de  lightgbm, con el metodo TRADICIONAL de los hiperparametros originales de lightgbm\n",
    "# 5-fold cross validation\n",
    "# la probabilidad de corte es un hiperparametro\n",
    "\n",
    "#limpio la memoria\n",
    "rm( list=ls() )  #remove all objects\n",
    "gc()             #garbage collection\n",
    "\n",
    "require(\"data.table\")\n",
    "require(\"rlist\")\n",
    "\n",
    "require(\"lightgbm\")\n",
    "\n",
    "#paquetes necesarios para la Bayesian Optimization\n",
    "require(\"DiceKriging\")\n",
    "require(\"mlrMBO\")\n",
    "\n",
    "options(error = function() { \n",
    "  traceback(20); \n",
    "  options(error = NULL); \n",
    "  stop(\"exiting after script error\") \n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2740799c-cd3a-45c7-9bb1-39db7082d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "setwd(\"~/buckets/b1/\")   #Establezco el Working Directory\n",
    "#setwd(\"C:/_MCD/Labo1/code\")  #Establezco el Working Directory\n",
    "\n",
    "kdataset       <- \"./datasets/competencia2_2022_limpieza1.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62eaa8f-254b-4c5c-818f-a6f498df9d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "kBO_iter  <- 100   #cantidad de iteraciones de la Optimizacion Bayesiana\n",
    "\n",
    "# ATENCION  si NO se quiere utilizar  undersampling  se debe  usar  kundersampling <- 1.0\n",
    "kundersampling  <- 1.0   # un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
    "\n",
    "prob_min  <- 0.5/( 1 + kundersampling*39)\n",
    "prob_max  <- pmin( 1.0, 4/( 1 + kundersampling*39) )\n",
    "\n",
    "#Aqui se cargan los hiperparametros\n",
    "hs <- makeParamSet( \n",
    "         makeNumericParam(\"learning_rate\",    lower=  0.01   , upper=    0.3),\n",
    "         makeNumericParam(\"feature_fraction\", lower=  0.2    , upper=    1.0),\n",
    "         makeIntegerParam(\"min_data_in_leaf\", lower=  0      , upper= 8000),\n",
    "         makeIntegerParam(\"num_leaves\",       lower= 16L     , upper= 1024L),\n",
    "         makeNumericParam(\"prob_corte\",       lower= prob_min, upper= prob_max  )  #esto sera visto en clase en gran detalle\n",
    "        )\n",
    "\n",
    "ksemilla_azar  <- 100019  #Aqui poner la propia semilla\n",
    "kexperimento   <- \"HT_DC\"\n",
    "ktraining      <- c( 202001,202002,202003,202004,202005,202007,202008,202009,202010,202011,202012,202101,202102,202103 )   #periodos en donde entreno\n",
    "\n",
    "kPOS_ganancia  <- 78000\n",
    "kNEG_ganancia  <- -2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b04c57-8794-4a7a-b2be-97ecb467c049",
   "metadata": {},
   "outputs": [],
   "source": [
    "loguear  <- function( reg, arch=NA, folder=\"./exp/\", ext=\".txt\", verbose=TRUE )\n",
    "{\n",
    "  archivo  <- arch\n",
    "  if( is.na(arch) )  archivo  <- paste0(  folder, substitute( reg), ext )\n",
    "\n",
    "  if( !file.exists( archivo ) )  #Escribo los titulos\n",
    "  {\n",
    "    linea  <- paste0( \"fecha\\t\", \n",
    "                      paste( list.names(reg), collapse=\"\\t\" ), \"\\n\" )\n",
    "\n",
    "    cat( linea, file=archivo )\n",
    "  }\n",
    "\n",
    "  linea  <- paste0( format(Sys.time(), \"%Y%m%d %H%M%S\"),  \"\\t\",     #la fecha y hora\n",
    "                    gsub( \", \", \"\\t\", toString( reg ) ),  \"\\n\" )\n",
    "\n",
    "  cat( linea, file=archivo, append=TRUE )  #grabo al archivo\n",
    "\n",
    "  if( verbose )  cat( linea )   #imprimo por pantalla\n",
    "}\n",
    "#------------------------------------------------------------------------------\n",
    "#esta funcion calcula internamente la ganancia de la prediccion probs\n",
    "\n",
    "fganancia_logistic_lightgbm   <- function( probs, datos) \n",
    "{\n",
    "  vlabels  <- get_field(datos, \"label\")\n",
    "  vpesos   <- get_field(datos, \"weight\")\n",
    "\n",
    "  gan  <- sum( (probs > PROB_CORTE  ) *\n",
    "               ifelse( vpesos == 1.0000002, kPOS_ganancia, \n",
    "                       ifelse( vpesos == 1.0000001, kNEG_ganancia, kNEG_ganancia / kundersampling ) ) )\n",
    "\n",
    "\n",
    "  return( list( \"name\"= \"ganancia\", \n",
    "                \"value\"=  gan,\n",
    "                \"higher_better\"= TRUE ) )\n",
    "}\n",
    "#------------------------------------------------------------------------------\n",
    "#esta funcion solo puede recibir los parametros que se estan optimizando\n",
    "#el resto de los parametros se pasan como variables globales, la semilla del mal ...\n",
    "\n",
    "EstimarGanancia_lightgbm  <- function( x )\n",
    "{\n",
    "  gc()  #libero memoria\n",
    "\n",
    "  #llevo el registro de la iteracion por la que voy\n",
    "  GLOBAL_iteracion  <<- GLOBAL_iteracion + 1\n",
    "\n",
    "  PROB_CORTE <<- x$prob_corte   #asigno la variable global\n",
    "\n",
    "  kfolds  <- 5   # cantidad de folds para cross validation\n",
    "\n",
    "  param_basicos  <- list( objective= \"binary\",\n",
    "                          metric= \"custom\",\n",
    "                          first_metric_only= TRUE,\n",
    "                          boost_from_average= TRUE,\n",
    "                          feature_pre_filter= FALSE,\n",
    "                          verbosity= -100,\n",
    "                          max_depth=  -1,         # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "                          min_gain_to_split= 0.0, #por ahora, lo dejo fijo\n",
    "                          lambda_l1= 0.0,         #por ahora, lo dejo fijo\n",
    "                          lambda_l2= 0.0,         #por ahora, lo dejo fijo\n",
    "                          max_bin= 31,            #por ahora, lo dejo fijo\n",
    "                          num_iterations= 9999,   #un numero muy grande, lo limita early_stopping_rounds\n",
    "                          force_row_wise= TRUE,   #para que los alumnos no se atemoricen con tantos warning\n",
    "                          seed= ksemilla_azar\n",
    "                        )\n",
    "\n",
    "  #el parametro discolo, que depende de otro\n",
    "  param_variable  <- list(  early_stopping_rounds= as.integer(50 + 5/x$learning_rate) )\n",
    "\n",
    "  param_completo  <- c( param_basicos, param_variable, x )\n",
    "\n",
    "  set.seed( ksemilla_azar )\n",
    "  modelocv  <- lgb.cv( data= dtrain,\n",
    "                       eval= fganancia_logistic_lightgbm,\n",
    "                       stratified= TRUE, #sobre el cross validation\n",
    "                       nfold= kfolds,    #folds del cross validation\n",
    "                       param= param_completo,\n",
    "                       verbose= -100\n",
    "                      )\n",
    "\n",
    "  #obtengo la ganancia\n",
    "  ganancia  <- unlist(modelocv$record_evals$valid$ganancia$eval)[ modelocv$best_iter ]\n",
    "\n",
    "  ganancia_normalizada  <-  ganancia* kfolds     #normailizo la ganancia\n",
    "\n",
    "  #el lenguaje R permite asignarle ATRIBUTOS a cualquier variable\n",
    "  attr(ganancia_normalizada ,\"extras\" )  <- list(\"num_iterations\"= modelocv$best_iter)  #esta es la forma de devolver un parametro extra\n",
    "\n",
    "  param_completo$num_iterations <- modelocv$best_iter  #asigno el mejor num_iterations\n",
    "  param_completo[\"early_stopping_rounds\"]  <- NULL     #elimino de la lista el componente  \"early_stopping_rounds\"\n",
    "\n",
    "  #logueo \n",
    "  xx  <- param_completo\n",
    "  xx$ganancia  <- ganancia_normalizada   #le agrego la ganancia\n",
    "  xx$iteracion <- GLOBAL_iteracion\n",
    "  loguear( xx, arch= klog )\n",
    "\n",
    "  return( ganancia_normalizada )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bce2833-e779-4f61-b9c2-ff203223aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargo el dataset donde voy a entrenar el modelo\n",
    "dataset  <- fread( kdataset)\n",
    "\n",
    "#creo la carpeta donde va el experimento\n",
    "# HT  representa  Hiperparameter Tuning\n",
    "\n",
    "#en estos archivos quedan los resultados\n",
    "kbayesiana  <- paste0( kexperimento, \".RDATA\" )\n",
    "klog        <- paste0( kexperimento, \".csv\" )\n",
    "\n",
    "\n",
    "GLOBAL_iteracion  <- 0   #inicializo la variable global\n",
    "\n",
    "#si ya existe el archivo log, traigo hasta donde llegue\n",
    "if( file.exists(klog) )\n",
    "{\n",
    "  tabla_log  <- fread( klog )\n",
    "  GLOBAL_iteracion  <- nrow( tabla_log )\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "#paso la clase a binaria que tome valores {0,1}  enteros\n",
    "dataset[ foto_mes %in% ktraining, clase01 := ifelse( clase_ternaria==\"CONTINUA\", 0L, 1L) ]\n",
    "\n",
    "\n",
    "#los campos que se van a utilizar\n",
    "campos_buenos  <- setdiff( colnames(dataset), c(\"clase_ternaria\",\"clase01\", \"azar\", \"training\",\"foto_mes\" ) )\n",
    "\n",
    "set.seed( ksemilla_azar )\n",
    "dataset[  , azar := runif( nrow( dataset ) ) ]\n",
    "dataset[  , training := 0L ]\n",
    "dataset[ foto_mes %in% ktraining & ( azar <= kundersampling | clase_ternaria %in% c( \"BAJA+1\", \"BAJA+2\" ) ), training := 1L ]\n",
    "\n",
    "#dejo los datos en el formato que necesita LightGBM\n",
    "dtrain  <- lgb.Dataset( data= data.matrix(  dataset[ training == 1L, campos_buenos, with=FALSE]),\n",
    "                        label= dataset[ training == 1L, clase01 ],\n",
    "                        weight=  dataset[ training == 1L, ifelse( clase_ternaria==\"BAJA+2\", 1.0000002, ifelse( clase_ternaria==\"BAJA+1\",  1.0000001, 1.0) )],\n",
    "                        free_raw_data= FALSE  )\n",
    "\n",
    "\n",
    "\n",
    "#Aqui comienza la configuracion de la Bayesian Optimization\n",
    "funcion_optimizar  <- EstimarGanancia_lightgbm   #la funcion que voy a maximizar\n",
    "\n",
    "configureMlr( show.learner.output= FALSE)\n",
    "\n",
    "#configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "#por favor, no desesperarse por lo complejo\n",
    "obj.fun  <- makeSingleObjectiveFunction(\n",
    "              fn=       funcion_optimizar, #la funcion que voy a maximizar\n",
    "              minimize= FALSE,   #estoy Maximizando la ganancia\n",
    "              noisy=    TRUE,\n",
    "              par.set=  hs,     #definido al comienzo del programa\n",
    "              has.simple.signature = FALSE   #paso los parametros en una lista\n",
    "             )\n",
    "\n",
    "ctrl  <- makeMBOControl( save.on.disk.at.time= 600,  save.file.path= kbayesiana)  #se graba cada 600 segundos\n",
    "ctrl  <- setMBOControlTermination(ctrl, iters= kBO_iter )   #cantidad de iteraciones\n",
    "ctrl  <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI() )\n",
    "\n",
    "#establezco la funcion que busca el maximo\n",
    "surr.km  <- makeLearner(\"regr.km\", predict.type= \"se\", covtype= \"matern3_2\", control= list(trace= TRUE))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9269643d-7fdb-407e-aa02-04e9a4ea3a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#inicio la optimizacion bayesiana\n",
    "if( !file.exists( kbayesiana ) ) {\n",
    "  run  <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
    "} else {\n",
    "  run  <- mboContinue( kbayesiana )   #retomo en caso que ya exista\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b34a20-7906-46de-99a0-5130e61022d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "quit( save=\"no\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
