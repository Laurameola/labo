{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b92488b5-f9e8-4e71-8e65-d29f1bbebcd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 604599</td><td>32.3</td><td>1292120</td><td>69.1</td><td>1292120</td><td>69.1</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>1087267</td><td> 8.3</td><td>8388608</td><td>64.0</td><td>1632674</td><td>12.5</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  604599 & 32.3 & 1292120 & 69.1 & 1292120 & 69.1\\\\\n",
       "\tVcells & 1087267 &  8.3 & 8388608 & 64.0 & 1632674 & 12.5\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |  604599 | 32.3 | 1292120 | 69.1 | 1292120 | 69.1 |\n",
       "| Vcells | 1087267 |  8.3 | 8388608 | 64.0 | 1632674 | 12.5 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
       "Ncells  604599 32.3 1292120    69.1 1292120  69.1\n",
       "Vcells 1087267  8.3 8388608    64.0 1632674  12.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: data.table\n",
      "\n",
      "Loading required package: rlist\n",
      "\n",
      "Loading required package: lightgbm\n",
      "\n",
      "Loading required package: R6\n",
      "\n",
      "Loading required package: DiceKriging\n",
      "\n",
      "Loading required package: mlrMBO\n",
      "\n",
      "Loading required package: mlr\n",
      "\n",
      "Loading required package: ParamHelpers\n",
      "\n",
      "Warning message: 'mlr' is in 'maintenance-only' mode since July 2019.\n",
      "Future development will only happen in 'mlr3'\n",
      "(<https://mlr3.mlr-org.com>). Due to the focus on 'mlr3' there might be\n",
      "uncaught bugs meanwhile in {mlr} - please consider switching.\n",
      "\n",
      "Loading required package: smoof\n",
      "\n",
      "Loading required package: checkmate\n",
      "\n",
      "\n",
      "Attaching package: 'checkmate'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:DiceKriging':\n",
      "\n",
      "    checkNames\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#limpio la memoria\n",
    "rm( list=ls() )  #remove all objects\n",
    "gc()             #garbage collection\n",
    "\n",
    "require(\"data.table\")\n",
    "require(\"rlist\")\n",
    "\n",
    "require(\"lightgbm\")\n",
    "\n",
    "#paquetes necesarios para la Bayesian Optimization\n",
    "require(\"DiceKriging\")\n",
    "require(\"mlrMBO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd7b8c8-ccd7-4b1a-8db0-2feb9d23ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "options(error = function() { \n",
    "  traceback(20); \n",
    "  options(error = NULL); \n",
    "  stop(\"exiting after script error\") \n",
    "})\n",
    "#------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05a3a10b-f9a8-42fc-87da-f6fb2484e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setwd(\"~/buckets/b1/\")\n",
    "setwd(\"C:/_MCD/Labo1/code\")  #Establezco el Working Directory\n",
    "\n",
    "#Parametros del script\n",
    "#kexperimento  <- \"comp1-HT-fe_inicial\"\n",
    "#dataset_input       <- \"./datasets/comp1/competencia1_2022_fe_inicial.csv\"\n",
    "\n",
    "#kexperimento  <- \"comp1-HT-fe_inicial_deflacion\"\n",
    "#dataset_input       <- \"./datasets/comp1/competencia1_2022_fe_inicial_deflacion.csv\"\n",
    "\n",
    "#kexperimento  <- \"comp1-HT-fe_inicial_rank0fijo\"\n",
    "#dataset_input       <- \"./datasets/comp1/competencia1_2022_fe_inicial_rank0fijo.csv\"\n",
    "\n",
    "#kexperimento  <- \"comp1-HT-fe_inicial_rank0simple\"\n",
    "#dataset_input       <- \"./datasets/comp1/competencia1_2022_fe_inicial_rank0simple.csv\"\n",
    "\n",
    "#kexperimento  <- \"comp1-HT-fe_alternativo1_rank0simple\"\n",
    "#dataset_input       <- \"./datasets/comp1/competencia1_2022_fe_alternativo1_rank0simple.csv\"\n",
    "\n",
    "kexperimento  <- \"comp1-HT-fe_alternativo1_rank0simple_optim\"\n",
    "dataset_input       <- \"./datasets/comp1/competencia1_2022_fe_alternativo1_rank0simple_optim.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0629a34c-3e6c-4797-b243-21cef3d66997",
   "metadata": {},
   "outputs": [],
   "source": [
    "ksemilla  <- 100019\n",
    "\n",
    "kcrossvalidation_folds  <- 5  #En caso que se haga cross validation, se usa esta cantidad de folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79d59718-2e02-4da5-a933-a5e36bf4fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#si usted es ambicioso, y tiene paciencia, podria subir este valor a 100\n",
    "kBO_iteraciones  <- 50  #iteraciones de la Optimizacion Bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "825c2428-b6b4-4bf1-a638-6592286f0f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hiperparametros FIJOS de  lightgbm\n",
    "param_lgb_basicos  <- list( \n",
    "   boosting= \"gbdt\",          #puede ir  dart  , ni pruebe random_forest\n",
    "   objective= \"binary\",\n",
    "   metric= \"custom\",\n",
    "   first_metric_only= TRUE,\n",
    "   boost_from_average= TRUE,\n",
    "   feature_pre_filter= FALSE,\n",
    "   force_row_wise= TRUE,      #para que los alumnos no se atemoricen con tantos warning\n",
    "   verbosity= -100,\n",
    "   max_depth=  -1,            # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "   min_gain_to_split= 0.0,    #por ahora, lo dejo fijo\n",
    "   lambda_l1= 0.0,            #por ahora, lo dejo fijo\n",
    "   lambda_l2= 0.0,            #por ahora, lo dejo fijo\n",
    "   max_bin= 31,               #por ahora, lo dejo fijo\n",
    "   num_iterations= 9999,      #un numero muy grande, lo limita early_stopping_rounds\n",
    "\n",
    "   bagging_fraction= 1.0,     #por ahora, lo dejo fijo\n",
    "   pos_bagging_fraction= 1.0, #por ahora, lo dejo fijo\n",
    "   neg_bagging_fraction= 1.0, #por ahora, lo dejo fijo\n",
    "\n",
    "   drop_rate=  0.1,           #solo se activa en  dart\n",
    "   max_drop= 50,              #solo se activa en  dart\n",
    "   skip_drop= 0.5,            #solo se activa en  dart\n",
    "\n",
    "   extra_trees= FALSE,\n",
    "\n",
    "   seed=  ksemilla\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79f58930-b97a-46b8-b4e2-1b21f8696c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui se cargan los hiperparametros que se optimizan en la Bayesian Optimization\n",
    "hs <- makeParamSet( \n",
    "         makeNumericParam(\"learning_rate\",    lower=    0.005, upper=    0.3),\n",
    "         makeNumericParam(\"feature_fraction\", lower=    0.2  , upper=    1.0),\n",
    "         makeIntegerParam(\"min_data_in_leaf\", lower=    0L   , upper=  8000L),\n",
    "         makeIntegerParam(\"num_leaves\",       lower=   16L   , upper=  2048L)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe471124-c7e4-46aa-91db-3a8f35380e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "#graba a un archivo los componentes de lista\n",
    "#para el primer registro, escribe antes los titulos\n",
    "\n",
    "exp_log  <- function( reg, arch=NA, folder=\"./exp/\", ext=\".txt\", verbose=TRUE )\n",
    "{\n",
    "  archivo  <- arch\n",
    "  if( is.na(arch) )  archivo  <- paste0(  folder, substitute( reg), ext )\n",
    "\n",
    "  if( !file.exists( archivo ) )  #Escribo los titulos\n",
    "  {\n",
    "    linea  <- paste0( \"fecha\\t\", \n",
    "                      paste( list.names(reg), collapse=\"\\t\" ), \"\\n\" )\n",
    "\n",
    "    cat( linea, file=archivo )\n",
    "  }\n",
    "\n",
    "  linea  <- paste0( format(Sys.time(), \"%Y%m%d %H%M%S\"),  \"\\t\",     #la fecha y hora\n",
    "                    gsub( \", \", \"\\t\", toString( reg ) ),  \"\\n\" )\n",
    "\n",
    "  cat( linea, file=archivo, append=TRUE )  #grabo al archivo\n",
    "\n",
    "  if( verbose )  cat( linea )   #imprimo por pantalla\n",
    "}\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "vprob_optima  <- c()\n",
    "\n",
    "fganancia_lgbm_meseta  <- function( probs, datos) \n",
    "{\n",
    "  vlabels  <- get_field(datos, \"label\")\n",
    "\n",
    "  tbl  <- as.data.table( list( \"prob\"= probs, \n",
    "                               \"gan\" = ifelse( vlabels==1 , 78000, -2000  ) ) )\n",
    "\n",
    "  setorder( tbl, -prob )\n",
    "  tbl[ , posicion := .I ]\n",
    "  tbl[ , gan_acum :=  cumsum( gan ) ]\n",
    "\n",
    "  gan  <-  tbl[ , max(gan_acum) ]\n",
    "\n",
    "  pos  <- which.max(  tbl[ , gan_acum ] ) \n",
    "  vprob_optima  <<- c( vprob_optima, tbl[ pos, prob ] )\n",
    "\n",
    "  rm( tbl )\n",
    "  return( list( \"name\"= \"ganancia\", \n",
    "                \"value\"=  gan,\n",
    "                \"higher_better\"= TRUE ) )\n",
    "}\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "EstimarGanancia_lightgbm  <- function( x )\n",
    "{\n",
    "  gc()\n",
    "  GLOBAL_iteracion  <<- GLOBAL_iteracion + 1\n",
    "\n",
    "  param_completo  <- c( param_lgb_basicos,  x )\n",
    "\n",
    "  param_completo$early_stopping_rounds  <- as.integer(200 + 4/param_completo$learning_rate )\n",
    "\n",
    "  vprob_optima  <<- c()\n",
    "  set.seed( param_completo$seed )\n",
    "  modelo_train  <- lgb.train( data= dtrain,\n",
    "                              valids= list( valid= dvalidate ),\n",
    "                              eval=   fganancia_lgbm_meseta,\n",
    "                              param=  param_completo,\n",
    "                              verbose= -100 )\n",
    "\n",
    "  prob_corte  <- vprob_optima[ modelo_train$best_iter ]\n",
    "\n",
    "  #aplico el modelo a testing y calculo la ganancia\n",
    "  prediccion  <- predict( modelo_train, \n",
    "                          data.matrix( dataset_test[ , campos_buenos, with=FALSE]) )\n",
    "\n",
    "  tbl  <- dataset_test[ , list(clase_ternaria) ]\n",
    "  tbl[ , prob := prediccion ]\n",
    "  ganancia_test  <- tbl[ prob >= prob_corte, \n",
    "                         sum( ifelse(clase_ternaria==\"BAJA+2\", 78000, -2000 ) )]\n",
    "\n",
    "  cantidad_test_normalizada  <- tbl[ prob >= prob_corte, .N ]\n",
    "\n",
    "  rm( tbl )\n",
    "  gc()\n",
    "\n",
    "  ganancia_test_normalizada  <- ganancia_test\n",
    "\n",
    "\n",
    "  #voy grabando las mejores column importance\n",
    "  if( ganancia_test_normalizada >  GLOBAL_ganancia )\n",
    "  {\n",
    "    GLOBAL_ganancia  <<- ganancia_test_normalizada\n",
    "    tb_importancia    <- as.data.table( lgb.importance( modelo_train ) )\n",
    "\n",
    "    fwrite( tb_importancia,\n",
    "            file= paste0( \"impo_\", GLOBAL_iteracion, \".txt\" ),\n",
    "            sep= \"\\t\" )\n",
    "\n",
    "    rm( tb_importancia )\n",
    "  }\n",
    "\n",
    "\n",
    "  #logueo final\n",
    "  ds  <- list( \"cols\"= ncol(dtrain),  \"rows\"= nrow(dtrain) )\n",
    "  xx  <- c( ds, copy(param_completo) )\n",
    "\n",
    "  xx$early_stopping_rounds  <- NULL\n",
    "  xx$num_iterations  <- modelo_train$best_iter\n",
    "  xx$prob_corte  <- prob_corte\n",
    "  xx$estimulos  <- cantidad_test_normalizada\n",
    "  xx$ganancia  <- ganancia_test_normalizada\n",
    "  xx$iteracion_bayesiana  <- GLOBAL_iteracion\n",
    "\n",
    "  exp_log( xx,  arch= \"BO_log.txt\" )\n",
    "\n",
    "  return( ganancia_test_normalizada )\n",
    "}\n",
    "#------------------------------------------------------------------------------\n",
    "#esta es la funcion mas mistica de toda la asignatura\n",
    "# sera explicada en  Laboratorio de Implementacion III\n",
    "\n",
    "vprob_optima  <- c()\n",
    "vpos_optima   <- c()\n",
    "\n",
    "fganancia_lgbm_mesetaCV  <- function( probs, datos) \n",
    "{\n",
    "  vlabels  <- get_field(datos, \"label\")\n",
    "  vpesos   <- get_field(datos, \"weight\")\n",
    "\n",
    "  tbl  <- as.data.table( list( \"prob\"= probs, \n",
    "                               \"gan\" = ifelse( vlabels==1 & vpesos > 1,\n",
    "                                               78000,\n",
    "                                               -2000  ) ) )\n",
    "\n",
    "  setorder( tbl, -prob )\n",
    "  tbl[ , posicion := .I ]\n",
    "  tbl[ , gan_acum :=  cumsum( gan ) ]\n",
    "\n",
    "  gan  <-  tbl[ , max(gan_acum) ]\n",
    "\n",
    "  pos  <- which.max(  tbl[ , gan_acum ] ) \n",
    "  vpos_optima   <<- c( vpos_optima, pos )\n",
    "  vprob_optima  <<- c( vprob_optima, tbl[ pos, prob ] )\n",
    "\n",
    "  rm( tbl )\n",
    "  return( list( \"name\"= \"ganancia\", \n",
    "                \"value\"=  gan,\n",
    "                \"higher_better\"= TRUE ) )\n",
    "}\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "EstimarGanancia_lightgbmCV  <- function( x )\n",
    "{\n",
    "  gc()\n",
    "  GLOBAL_iteracion  <<- GLOBAL_iteracion + 1\n",
    "\n",
    "  param_completo  <- c(param_lgb_basicos,  x )\n",
    "\n",
    "  param_completo$early_stopping_rounds  <- as.integer(200 + 4/param_completo$learning_rate )\n",
    "\n",
    "  vprob_optima  <<- c()\n",
    "  vpos_optima   <<- c()\n",
    "\n",
    "  set.seed( param_completo$seed )\n",
    "  modelocv  <- lgb.cv( data= dtrain,\n",
    "                       eval=   fganancia_lgbm_mesetaCV,\n",
    "                       param=  param_completo,\n",
    "                       stratified= TRUE,                   #sobre el cross validation\n",
    "                       nfold= kcrossvalidation_folds,\n",
    "                       verbose= -100 )\n",
    "\n",
    "  desde  <- (modelocv$best_iter-1)*kcrossvalidation_folds + 1\n",
    "  hasta  <- desde + kcrossvalidation_folds -1\n",
    "\n",
    "  prob_corte            <-  mean( vprob_optima[ desde:hasta ] )\n",
    "  cantidad_normalizada  <-  mean( vpos_optima[ desde:hasta ] ) * kcrossvalidation_folds\n",
    "\n",
    "  ganancia  <- unlist(modelocv$record_evals$valid$ganancia$eval)[ modelocv$best_iter ]\n",
    "  ganancia_normalizada  <- ganancia * kcrossvalidation_folds\n",
    "\n",
    "\n",
    "  #voy grabando las mejores column importance\n",
    "  if( ganancia_normalizada >  GLOBAL_ganancia )\n",
    "  {\n",
    "    GLOBAL_ganancia  <<- ganancia_normalizada\n",
    "\n",
    "    param_impo <-  copy( param_completo )\n",
    "    param_impo$early_stopping_rounds  <- 0\n",
    "    param_impo$num_iterations  <- modelocv$best_iter\n",
    "\n",
    "    modelo  <- lgb.train( data= dtrain,\n",
    "                       param=  param_impo,\n",
    "                       verbose= -100 )\n",
    "\n",
    "    tb_importancia    <- as.data.table( lgb.importance( modelo ) )\n",
    "\n",
    "    fwrite( tb_importancia,\n",
    "            file= paste0( \"impo_\", GLOBAL_iteracion, \".txt\" ),\n",
    "            sep= \"\\t\" )\n",
    "    \n",
    "    rm( tb_importancia )\n",
    "  }\n",
    "\n",
    "\n",
    "  #logueo final\n",
    "  ds  <- list( \"cols\"= ncol(dtrain),  \"rows\"= nrow(dtrain) )\n",
    "  xx  <- c( ds, copy(param_completo) )\n",
    "\n",
    "  xx$early_stopping_rounds  <- NULL\n",
    "  xx$num_iterations  <- modelocv$best_iter\n",
    "  xx$prob_corte  <-  prob_corte\n",
    "  xx$estimulos   <-  cantidad_normalizada\n",
    "  xx$ganancia  <- ganancia_normalizada\n",
    "  xx$iteracion_bayesiana  <- GLOBAL_iteracion\n",
    "\n",
    "  exp_log( xx,  arch= \"BO_log.txt\" )\n",
    "\n",
    "  return( ganancia_normalizada )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4562ea2c-66ab-4d2b-a60e-506f1d372a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td>2164758</td><td>115.7</td><td> 4359737</td><td>232.9</td><td> 3156286</td><td>168.6</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>9792715</td><td> 74.8</td><td>28709271</td><td>219.1</td><td>23501798</td><td>179.4</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells & 2164758 & 115.7 &  4359737 & 232.9 &  3156286 & 168.6\\\\\n",
       "\tVcells & 9792715 &  74.8 & 28709271 & 219.1 & 23501798 & 179.4\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells | 2164758 | 115.7 |  4359737 | 232.9 |  3156286 | 168.6 |\n",
       "| Vcells | 9792715 |  74.8 | 28709271 | 219.1 | 23501798 | 179.4 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb)  gc trigger (Mb)  max used (Mb) \n",
       "Ncells 2164758 115.7  4359737   232.9  3156286 168.6\n",
       "Vcells 9792715  74.8 28709271   219.1 23501798 179.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------\n",
    "#Aqui empieza el programa\n",
    "\n",
    "\n",
    "#cargo el dataset donde voy a entrenar\n",
    "#esta en la carpeta del exp_input y siempre se llama  dataset_training.csv.gz\n",
    "dataset  <- fread( dataset_input )\n",
    "\n",
    "#creo la carpeta donde va el experimento\n",
    "dir.create( paste0( \"./exp/\", kexperimento, \"/\"), showWarnings = FALSE )\n",
    "setwd(paste0( \"./exp/\", kexperimento, \"/\"))   #Establezco el Working Directory DEL EXPERIMENTO\n",
    "\n",
    "#defino la clase binaria clase01\n",
    "dataset[  , clase01 := ifelse( clase_ternaria==\"CONTINUA\", 0L, 1L ) ]\n",
    "\n",
    "\n",
    "#los campos que se pueden utilizar para la prediccion\n",
    "campos_buenos  <- setdiff( copy(colnames( dataset )), c( \"clase01\", \"clase_ternaria\" ) )\n",
    "\n",
    "#la particion de train siempre va\n",
    "dtrain  <- lgb.Dataset( data=    data.matrix( dataset[ foto_mes==202101, campos_buenos, with=FALSE] ),\n",
    "                        label=   dataset[ foto_mes==202101, clase01 ],\n",
    "                        weight=  dataset[ foto_mes==202101, ifelse( clase_ternaria == \"BAJA+2\", 1.0000001, 1.0) ],\n",
    "                        free_raw_data= FALSE\n",
    "                      )\n",
    "\n",
    "kcrossvalidation  <- TRUE\n",
    "\n",
    "rm( dataset )\n",
    "gc()\n",
    "\n",
    "\n",
    "#si ya existe el archivo log, traigo hasta donde procese\n",
    "if( file.exists( \"BO_log.txt\" ) )\n",
    "{\n",
    "  tabla_log  <- fread( \"BO_log.txt\" )\n",
    "  GLOBAL_iteracion  <- nrow( tabla_log )\n",
    "  GLOBAL_ganancia   <- tabla_log[ , max(ganancia) ]\n",
    "  rm(tabla_log)\n",
    "} else  {\n",
    "  GLOBAL_iteracion  <- 0\n",
    "  GLOBAL_ganancia   <- -Inf\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18d98c-9750-4428-be7d-5be83927e46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing y column(s) for design. Not provided.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Aqui comienza la configuracion de mlrMBO\n",
    "\n",
    "#deobo hacer cross validation o  Train/Validate/Test\n",
    "if( kcrossvalidation ) {\n",
    "  funcion_optimizar  <- EstimarGanancia_lightgbmCV\n",
    "} else {\n",
    "  funcion_optimizar  <- EstimarGanancia_lightgbm\n",
    "}\n",
    "\n",
    "\n",
    "configureMlr( show.learner.output= FALSE)\n",
    "\n",
    "#configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "#por favor, no desesperarse por lo complejo\n",
    "obj.fun  <- makeSingleObjectiveFunction(\n",
    "              fn=       funcion_optimizar, #la funcion que voy a maximizar\n",
    "              minimize= FALSE,   #estoy Maximizando la ganancia\n",
    "              noisy=    TRUE,\n",
    "              par.set=  hs,     #definido al comienzo del programa\n",
    "              has.simple.signature = FALSE   #paso los parametros en una lista\n",
    "             )\n",
    "\n",
    "#archivo donde se graba y cada cuantos segundos\n",
    "ctrl  <- makeMBOControl( save.on.disk.at.time= 600,  \n",
    "                         save.file.path=       \"bayesiana.RDATA\" )\n",
    "                         \n",
    "ctrl  <- setMBOControlTermination( ctrl, \n",
    "                                   iters= kBO_iteraciones )   #cantidad de iteraciones\n",
    "                                   \n",
    "ctrl  <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI() )\n",
    "\n",
    "#establezco la funcion que busca el maximo\n",
    "surr.km  <- makeLearner(\"regr.km\",\n",
    "                        predict.type= \"se\",\n",
    "                        covtype= \"matern3_2\",\n",
    "                        control= list(trace= TRUE) )\n",
    "\n",
    "\n",
    "\n",
    "#Aqui inicio la optimizacion bayesiana\n",
    "if( !file.exists( \"bayesiana.RDATA\" ) ) {\n",
    "\n",
    "  run  <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
    "\n",
    "} else {\n",
    "  #si ya existe el archivo RDATA, debo continuar desde el punto hasta donde llegue\n",
    "  #  usado para cuando se corta la virtual machine\n",
    "  run  <- mboContinue( \"bayesiana.RDATA\" )   #retomo en caso que ya exista\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
